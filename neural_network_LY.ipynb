{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b40dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50b4415",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "432b1cbc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>A</th>\n",
       "      <th>AA</th>\n",
       "      <th>AAL</th>\n",
       "      <th>AAP</th>\n",
       "      <th>AAPL</th>\n",
       "      <th>AAS</th>\n",
       "      <th>ABBV</th>\n",
       "      <th>ABC</th>\n",
       "      <th>ABMD</th>\n",
       "      <th>...</th>\n",
       "      <th>XOM</th>\n",
       "      <th>XRAY</th>\n",
       "      <th>XYL</th>\n",
       "      <th>YUM</th>\n",
       "      <th>ZBH</th>\n",
       "      <th>ZBRA</th>\n",
       "      <th>ZION</th>\n",
       "      <th>ZMH</th>\n",
       "      <th>ZMX</th>\n",
       "      <th>ZTS</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2001-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.070776</td>\n",
       "      <td>-0.037313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.011139</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.072165</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025162</td>\n",
       "      <td>-0.003195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032197</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038682</td>\n",
       "      <td>-0.040040</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.103194</td>\n",
       "      <td>0.013566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.100840</td>\n",
       "      <td>0.020025</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.094444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.043478</td>\n",
       "      <td>-0.051282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.056751</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.107670</td>\n",
       "      <td>0.033368</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.037862</td>\n",
       "      <td>0.032505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041985</td>\n",
       "      <td>-0.082209</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.081218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.027859</td>\n",
       "      <td>-0.064189</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.003995</td>\n",
       "      <td>-0.020182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.011628</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-05</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.054721</td>\n",
       "      <td>-0.018519</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.040293</td>\n",
       "      <td>-0.034759</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.104972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004525</td>\n",
       "      <td>0.010830</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.031423</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.029412</td>\n",
       "      <td>-0.011329</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2001-01-08</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032917</td>\n",
       "      <td>0.015094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011450</td>\n",
       "      <td>0.060942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.185185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.004505</td>\n",
       "      <td>0.030357</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.005725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.015152</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017647</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 667 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         A        AA  AAL  AAP      AAPL       AAS  ABBV  ABC  \\\n",
       "date                                                                           \n",
       "2001-01-02  0.0 -0.070776 -0.037313  0.0  0.0  0.000000 -0.011139   0.0  0.0   \n",
       "2001-01-03  0.0  0.103194  0.013566  0.0  0.0  0.100840  0.020025   0.0  0.0   \n",
       "2001-01-04  0.0  0.037862  0.032505  0.0  0.0  0.041985 -0.082209   0.0  0.0   \n",
       "2001-01-05  0.0 -0.054721 -0.018519  0.0  0.0 -0.040293 -0.034759   0.0  0.0   \n",
       "2001-01-08  0.0 -0.032917  0.015094  0.0  0.0  0.011450  0.060942   0.0  0.0   \n",
       "\n",
       "                ABMD  ...       XOM      XRAY  XYL       YUM  ZBH      ZBRA  \\\n",
       "date                  ...                                                     \n",
       "2001-01-02 -0.072165  ...  0.025162 -0.003195  0.0 -0.032197  0.0  0.038682   \n",
       "2001-01-03  0.094444  ... -0.043478 -0.051282  0.0  0.056751  0.0  0.107670   \n",
       "2001-01-04 -0.081218  ... -0.027859 -0.064189  0.0  0.001852  0.0 -0.003995   \n",
       "2001-01-05 -0.104972  ...  0.004525  0.010830  0.0 -0.031423  0.0 -0.029412   \n",
       "2001-01-08 -0.185185  ... -0.004505  0.030357  0.0 -0.005725  0.0 -0.015152   \n",
       "\n",
       "                ZION  ZMH       ZMX  ZTS  \n",
       "date                                      \n",
       "2001-01-02 -0.040040  0.0  0.000000  0.0  \n",
       "2001-01-03  0.033368  0.0  0.000000  0.0  \n",
       "2001-01-04 -0.020182  0.0 -0.011628  0.0  \n",
       "2001-01-05 -0.011329  0.0  0.000000  0.0  \n",
       "2001-01-08  0.002083  0.0  0.017647  0.0  \n",
       "\n",
       "[5 rows x 667 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"data/returns.csv\"\n",
    "returns = pd.read_csv(path, index_col=0, parse_dates=True)\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe7143b",
   "metadata": {},
   "source": [
    "additional cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5070d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pre_ipo(df):\n",
    "    # For each stock, treat leading zeros as NA\n",
    "    df2 = df.copy()\n",
    "    for col in df2:\n",
    "        s = df2[col]\n",
    "        first_nonzero = s.ne(0).idxmax()  # first non-zero return\n",
    "        df2.loc[:first_nonzero, col] = np.nan\n",
    "    return df2\n",
    "\n",
    "def safe_rolling_zscore(df, window):\n",
    "    rolling_mean = df.rolling(window).mean()\n",
    "    rolling_std = df.rolling(window).std()\n",
    "\n",
    "    # If std == 0 → return 0 instead of NaN or inf\n",
    "    z = (df - rolling_mean) / rolling_std.replace(0, np.nan)\n",
    "    z = z.fillna(0)\n",
    "\n",
    "    return z\n",
    "\n",
    "\n",
    "# 1. Mask pre-IPO zeros  \n",
    "returns = mask_pre_ipo(returns)\n",
    "\n",
    "# 2. Compute stable rolling z  \n",
    "features = safe_rolling_zscore(returns, window=60)\n",
    "\n",
    "# 3. Replace infinities / residual NaN  \n",
    "features = features.replace([np.inf, -np.inf], 0).fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c745c23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 010 | Train Loss 61.328948\n",
      "Epoch 020 | Train Loss 57.995537\n",
      "Epoch 030 | Train Loss 56.978979\n",
      "Epoch 040 | Train Loss 56.403842\n",
      "Epoch 050 | Train Loss 55.906245\n",
      "Epoch 060 | Train Loss 55.699430\n",
      "Epoch 070 | Train Loss 55.802527\n",
      "Epoch 080 | Train Loss 55.739613\n",
      "Epoch 090 | Train Loss 55.585155\n",
      "Epoch 100 | Train Loss 56.064026\n",
      "\n",
      "Train R² = 0.0734\n",
      " Test R² = -0.0649\n"
     ]
    }
   ],
   "source": [
    "\n",
    "returns = features\n",
    "\n",
    "# Assume `returns` is a (T, N) pandas DataFrame, indexed by date\n",
    "X_all = torch.tensor(returns.shift(1).iloc[1:].values, dtype=torch.float32)  # r_t\n",
    "y_all = torch.tensor(returns.iloc[1:].values, dtype=torch.float32)           # r_{t+1}\n",
    "T, N = X_all.shape\n",
    "\n",
    "# --------------- Train/Test Split (preserve order) ---------------\n",
    "split_idx = int(T * 0.8)\n",
    "X_train, X_test = X_all[:split_idx], X_all[split_idx:]\n",
    "y_train, y_test = y_all[:split_idx], y_all[split_idx:]\n",
    "\n",
    "# --------------- Normalize using training set only ---------------\n",
    "\n",
    "# mean = X_train.mean(0, keepdim=True)\n",
    "# std = X_train.std(0, keepdim=True) + 1e-6\n",
    "# X_train = (X_train - mean) / std\n",
    "# y_train = (y_train - mean) / std\n",
    "# X_test = (X_test - mean) / std\n",
    "# y_test = (y_test - mean) / std\n",
    "\n",
    "# --------------- Neural Network Definition ---------------\n",
    "class ReturnPredictor(nn.Module):\n",
    "    def __init__(self, N, hidden_dim=256, depth=3, dropout=0.1):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        in_dim = N\n",
    "        for _ in range(depth):\n",
    "            layers += [\n",
    "                nn.Linear(in_dim, hidden_dim),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(dropout),\n",
    "                nn.BatchNorm1d(hidden_dim)\n",
    "            ]\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, N))  # output dimension N\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "model = ReturnPredictor(N, hidden_dim=3, depth=2)\n",
    "# Custom loss combining MSE and hit rate\n",
    "def combined_loss(y_pred, y_true, mse_weight=0.5, hit_weight=100):\n",
    "    # MSE component\n",
    "    mse = torch.mean((y_pred - y_true) ** 2)\n",
    "    \n",
    "    # Hit rate component (penalize incorrect sign predictions)\n",
    "    # We want to maximize hit rate, so we minimize (1 - hit_rate)\n",
    "    correct_signs = (torch.sign(y_pred) == torch.sign(y_true)).float()\n",
    "    hit_rate = torch.mean(correct_signs)\n",
    "    hit_loss = 1 - hit_rate\n",
    "    \n",
    "    # Normalize MSE to be on similar scale as hit_loss (which is in [0, 1])\n",
    "    # Use detach to avoid affecting gradients of the normalization factor\n",
    "    mse_normalized = mse / (mse.detach() + 1e-8)\n",
    "    \n",
    "    # Combined loss with normalized components\n",
    "    return mse_weight * mse_normalized + hit_weight * hit_loss\n",
    "\n",
    "criterion = combined_loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# --------------- Training Loop ---------------\n",
    "n_epochs = 100\n",
    "batch_size = 32\n",
    "T_train = len(X_train)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(0, T_train, batch_size):\n",
    "        Xb = X_train[i:i+batch_size]\n",
    "        yb = y_train[i:i+batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(Xb)\n",
    "        loss = criterion(y_pred, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * len(Xb)\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        avg_loss = total_loss / T_train\n",
    "        print(f\"Epoch {epoch+1:03d} | Train Loss {avg_loss:.6f}\")\n",
    "\n",
    "# --------------- Evaluation ---------------\n",
    "with torch.no_grad():\n",
    "    y_pred_train = model(X_train)\n",
    "    y_pred_test = model(X_test)\n",
    "\n",
    "def r2_score(y_true, y_pred):\n",
    "    ss_res = ((y_true - y_pred)**2).sum().item()\n",
    "    ss_tot = ((y_true)**2).sum().item()\n",
    "    return 1 - ss_res / ss_tot\n",
    "\n",
    "r2_train = r2_score(y_train, y_pred_train)\n",
    "r2_test  = r2_score(y_test,  y_pred_test)\n",
    "\n",
    "print(f\"\\nTrain R² = {r2_train:.4f}\")\n",
    "print(f\" Test R² = {r2_test:.4f}\")\n",
    "\n",
    "# --------------- Convert predictions back to DataFrame ---------------\n",
    "# y_hat_test = (y_pred_test * std + mean).numpy()\n",
    "# pred_df = pd.DataFrame(\n",
    "#     y_hat_test,\n",
    "#     index=returns.index[1:][split_idx:],\n",
    "#     columns=returns.columns\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b64c1a53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Hit Rate = 0.4429\n",
      " Test Hit Rate = 0.3851\n"
     ]
    }
   ],
   "source": [
    "# --------------- Hit Rate Calculation ---------------\n",
    "# Hit rate: percentage of times the predicted sign matches the actual sign\n",
    "def hit_rate(y_true, y_pred):\n",
    "    correct = ((y_true * y_pred) > 0).sum().item()\n",
    "    total = y_true.numel()\n",
    "    return correct / total\n",
    "\n",
    "hit_rate_train = hit_rate(y_train, y_pred_train)\n",
    "hit_rate_test = hit_rate(y_test, y_pred_test)\n",
    "\n",
    "print(f\"\\nTrain Hit Rate = {hit_rate_train:.4f}\")\n",
    "print(f\" Test Hit Rate = {hit_rate_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10899d73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
